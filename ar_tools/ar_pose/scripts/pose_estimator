#!/usr/bin/env python

"""
Author: Anna Lee
Modified from Jonathan Kim's code.
"""

import rospy
import roslib; roslib.load_manifest('ar_pose')
import tf
import image_geometry
import math
from ar_pose.msg import ARMarker
from ar_pose.msg import ARMarkers
from geometry_msgs.msg import *
from sensor_msgs.msg import *

# The longest time to wait before broadcasting a marker, even if it is not stereo
MS = 1000000 # in ns
LONGEST_STEREO_WAIT = 500 * MS # in ns
class Algorithm:
    Stereo = 0
    Average = 1
    Left = 2
ALGORITHM = Algorithm.Stereo
MIN_CONFIDENCE = 80

ids_to_joints = {0: "left gripper",
                 1: "coke can"}

# takes in two quaternions and returns their dot product
def quat_dot_product(q1, q2):
    return q1.x*q2.x + q1.y*q2.y + q1.z*q2.z +q1.w*q2.w

# finds the SLERP interpolation between two quaternions
def slerp(q1, q2, t):
    dot_product = quat_dot_product(q1,q2)
    theta = math.acos(dot_product)
    x = (math.sin((1-t)*theta)/math.sin(theta))*q1.x + (math.sin(t*theta)/math.sin(theta))*q2.x
    y = (math.sin((1-t)*theta)/math.sin(theta))*q1.y + (math.sin(t*theta)/math.sin(theta))*q2.y
    z = (math.sin((1-t)*theta)/math.sin(theta))*q1.z + (math.sin(t*theta)/math.sin(theta))*q2.z
    w = (math.sin((1-t)*theta)/math.sin(theta))*q1.w + (math.sin(t*theta)/math.sin(theta))*q2.w
    result = Quaternion()
    result.x = x
    result.y = y
    result.z = z
    result.w = w
    return result

def position_avg(p1, p2):
    return Point((p1.x+p2.x)/2.0, (p1.y+p2.y)/2.0, (p1.z+p2.z)/2.0)

def quaternion_avg(q1, q2):
    return slerp(q1, q2, 0.5)
    #return Quaternion((q1.x+q2.x)/2.0, (q1.y+q2.y)/2.0, (q1.z+q2.z)/2.0,\
    #        (q1.w+q2.w)/2.0)

def pos_tuple(p1):
    return (p1.x, p1.y, p1.z)

def ori_tuple(q1):
    return (q1.x, q1.y, q1.z, q1.w)

def pos_add(p1, offset):
    pos = Point()
    pos.x = p1.x + offset[0]
    pos.y = p1.y + offset[1]
    pos.z = p1.z + offset[2]
    return pos

# tuple
def pos_diff(p1, p2):
    return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2 + (p1[2] - p2[2])**2)**0.5

# tuple
def ori_diff(o1, o2):
    return ((o1[0] - o2[0])**2 + (o1[1] - o2[1])**2 + (o1[2] - o2[2])**2\
            + (o1[3] - o2[3])**2)**0.5

# TODO: output frame, camera frame don't actually do anything right now and must be the same
# in take_average
class PoseEstimator:
    def __init__(self, output_frame, camera_frame):
        self.camera_info = {}
        self.transform_listener = tf.TransformListener()
        self.broadcaster = tf.TransformBroadcaster()
        self.right_poses_dict = {}
        self.left_poses_dict = {}
        self.output_frame = output_frame
        self.camera_frame = camera_frame
        self.last_stereo_marker_time = rospy.Time.now()
        self.poses = []
        
        right_frame = 'wide_stereo_gazebo_r_stereo_camera_frame'
        left_frame = 'wide_stereo_gazebo_l_stereo_camera_frame'
        #self.transform_listener.waitForTransform(right_frame, left_frame, rospy.Time(), rospy.Duration(4.0))
        #(self.right_offset, rot) = self.transform_listener.lookupTransform(left_frame, right_frame, rospy.Time())
        self.right_offset = (0,0,0)

        self.publisher = rospy.Publisher("stereo_pose", ARMarkers)

        self.left_point_subscriber = rospy.Subscriber("ar_pose_marker", ARMarkers, self.left_handle_markers)
        self.right_point_subscriber = rospy.Subscriber("ar_pose_marker_r", ARMarkers, self.right_handle_markers)
        self.left_camera_info_subscriber = rospy.Subscriber("wide_stereo/left/camera_info", CameraInfo, self.handle_camera_info('left'));
        self.right_camera_info_subscriber = rospy.Subscriber("wide_stereo/right/camera_info", CameraInfo, self.handle_camera_info('right'));

    def handle_camera_info(self, camera):
        def handler(camera_info):
            self.camera_info[camera] = camera_info
        return handler
            
    # called when a list of AR markers is published for the right camera
    # stores poses in a dictionary that maps from id number to pose
    def right_handle_markers(self, markers):
        for marker in markers.markers:
            if marker.confidence >= MIN_CONFIDENCE:
                self.right_poses_dict[marker.id] = marker
        self.handle_both()

    # called when a list of AR markers is published for the left camera
    # stores poses in a dictionary that maps from id number to pose
    def left_handle_markers(self, markers):
        for marker in markers.markers:
            if marker.confidence >= MIN_CONFIDENCE:
                self.left_poses_dict[marker.id] = marker
        self.handle_both()

    # waits until there are values in both right_poses_dict and left_poses_dict
    # calls helper functions to calculate more accurate poses, and publishes those poses
    # then clears the dictionaries
    def handle_both(self):
        if self.right_poses_dict and self.left_poses_dict:
            self.calculate_poses()
            self.publish()
            self.left_poses_dict = {}
            self.right_poses_dict = {}              
        elif ((rospy.Time.now().secs - self.last_stereo_marker_time.secs > 1) or
              (rospy.Time.now().nsecs - self.last_stereo_marker_time.nsecs) > LONGEST_STEREO_WAIT):
            self.calculate_nonstereo_pose()
            self.publish()
            self.left_poses_dict = {}
            self.right_poses_dict = {}

    def calculate_nonstereo_pose(self):
        poses = []
        if self.left_poses_dict:
            for marker in self.left_poses_dict.values():
                poses.append(marker)
        else:
            for marker in self.right_poses_dict.values():
                poses.append(marker)
        self.poses = poses
    
    # goes through the poses in the right_poses_dict and the left_poses_dict and calculates 
    # a more accurate value for them; calls the helper function convert_stereo
    def calculate_poses(self):
        poses = []
        for id_number in self.right_poses_dict.iterkeys():
            if id_number in self.left_poses_dict.keys():
                left_marker = self.left_poses_dict[id_number]
                right_marker = self.right_poses_dict[id_number]
                if ALGORITHM == Algorithm.STEREO:
                    marker = self.convert_stereo(left_marker, right_marker)
                elif ALGORITHM == Algorithm.AVERAGE:
                    marker = self.take_average_marker(left_marker, right_marker) 
                elif ALGORITHM == Algorithm.LEFT:
                    marker = left_marker
                marker.header.stamp = left_marker.header.stamp
                marker.id = id_number
                poses.append(marker)
        self.poses = poses
    
    # publishes the message with joints and poses
    def publish(self):
        poses = ARMarkers()
        poses.header.stamp = rospy.Time.now()
        poses.header.frame_id = self.output_frame
        for marker in self.poses:
            pose = marker.pose.pose
            poses.markers.append(marker)
            self.broadcaster.sendTransform(pos_tuple(pose.position), ori_tuple(pose.orientation), marker.header.stamp, 'ar_stereo_' + str(marker.id), self.output_frame)

        self.publisher.publish(poses)
        self.last_stereo_marker_time = rospy.Time.now()

    def take_average_marker(self, p1, p2):
        pose = self.take_average_pose(p1.pose.pose, p2.pose.pose)
        marker = ARMarker()
        marker.header.frame_id = self.output_frame
        marker.pose.pose = pose
        return marker

    def take_average_pose(self, p1, p2):
        pos_avg = position_avg(p1.position, p2.position)
        #ori_avg = quaternion_avg(p1.orientation, p2.orientation)
        ori_avg = p1.orientation
        pose = Pose()
        pose.position = pos_avg
        pose.orientation = ori_avg
        return pose

    # takes in two poses and returns a more accurate pose based on their values 
    # uses the stereo_model object from the image_geometry module for calculations
    def convert_stereo(self,marker1,marker2):
        p1 = marker1.pose
        p2 = marker2.pose
        u = p1.pose.position.x
        v = p2.pose.position.y
        disparity = p1.pose.position.x - p2.pose.position.x
        
        stereo_model = image_geometry.StereoCameraModel()
        stereo_model.fromCameraInfo(self.camera_info['left'], self.camera_info['right'])
        (x,y,z) = stereo_model.projectPixelTo3d((u,v),disparity)

        accurate_pose = Pose()
        marker = ARMarker()
        marker.header.frame_id = self.camera_frame
        marker.header.stamp = p1.header.stamp
        accurate_pose.position.x = x
        accurate_pose.position.y = y
        accurate_pose.position.z = z
        accurate_pose.orientation.x = p1.orientation.x
        accurate_pose.orientation.y = p1.orientation.y
        accurate_pose.orientation.z = p1.orientation.z
        accurate_pose.orientation.w = p1.orientation.w
        marker.pose.pose = accurate_pose

        return marker
        #self.transform_listener.waitForTransform(self.output_frame, self.camera_frame, rospy.Time.now(), rospy.Duration(4.0))
        #output_pose = self.listener.transformPose(self.output_frame, accurate_pose)
        #return output_pose


def main():
    rospy.init_node("pose_estimator")
    outputframe = rospy.get_param('~output_frame',"wide_stereo_optical_frame")
    camera_frame = rospy.get_param('~camera_frame', "wide_stereo_optical_frame")
    p = PoseEstimator(outputframe, camera_frame)
    print "starting to spin"
    rospy.spin()


if __name__=='__main__':
    main()


