#!/usr/bin/env python

# Import required Python code.
import roslib
import argparse
roslib.load_manifest('raven_pose_estimator')
import rospy

from raven_pose_estimator.srv import *
import cv
import cv2
import numpy as np
from scipy import linalg
import math
from std_msgs.msg import String
from sensor_msgs.msg import Image, CameraInfo
import cv_bridge
from geometry_msgs.msg import Point, PointStamped, Quaternion, PoseStamped, Polygon, PolygonStamped, Point32
import tf
import image_geometry
import time

import message_filters
from threading import Lock

import tf.transformations as tft
import tfx

import IPython

# adapted and adjusted from Greg Kahn's code (ImageProcessing.py)

########################################
#             CONSTANTS                #
########################################

# right gripper
GREEN_LOWER = cv.Scalar(38, 50, 50) #THESE ARE THE GREEN PAPER VALUES
GREEN_UPPER = cv.Scalar(95, 255, 255)
ORANGE_LOWER = cv.Scalar(5, 40, 200) # THESE ARE THE ORANGE PAPER VALUES
ORANGE_UPPER = cv.Scalar(30, 255, 255)

# left gripper
PURPLE_LOWER = cv.Scalar(120, 25, 90)
PURPLE_UPPER = cv.Scalar(170, 255, 255)
BLUE_LOWER = cv.Scalar(96, 45, 120)
BLUE_UPPER = cv.Scalar(120, 255, 255)

# TEMP: since only for one gripper at a time
#GREEN_LOWER = PURPLE_LOWER
#GREEN_UPPER = PURPLE_UPPER
#ORANGE_LOWER = BLUE_LOWER
#ORANGE_UPPER = BLUE_UPPER

RED_LOWER = cv.Scalar(0, 100, 30) # VALUES FOR THE RED FOAM
RED_UPPER = cv.Scalar(3, 255, 255)
WIDTH_ROI = 600
HEIGHT_ROI = 600
SLERP = True
DYNAMIC_SLERP = False
SLERP_CONSTANT = 0.1




########################################
#     3D GEOMETRY HELPER METHODS       #
########################################


def calculateSLERPConstant(angle):
    return math.fabs(angle/360)

def angleBetweenQuaternions(quat0, quat1):
    """ 
    Returns angle between quat0 and quat1 in degrees 
    """
    q0 = np.array(quat0)
    q1 = np.array(quat1)
    theta = math.acos(2*np.dot(q0,q1)**2 - 1)
    theta = theta*(180.0/math.pi)
    return theta



def order_points(p1, p2):
    """ 
    Takes in two points of form (x,y) and orders them according to y-coordinate value 
    """
    if p1[1] > p2[1]:
        return p1,p2
    elif p1[1] < p2[1]:
        return p2,p1
    else:
        return p1,p2



def find_endpoints(contours):
    """ 
    Takes in a list of contours and returns the pixel coordinates of centroids of the top two contours 
    """
    if len(contours) < 2:
        return (0,0,False)
    contours.sort(key=len, reverse=True)
    points = []
    for c in contours:
        moments = cv2.moments(c)
        if moments['m00']!=0:
            cx = int(moments['m10']/moments['m00'])     
            cy = int(moments['m01']/moments['m00'])        
            points.append((cx, cy))
    try:
        upper_pt, lower_pt = order_points(points[0], points[1])
        return (lower_pt, upper_pt, True)
    except IndexError as e:
        return (0,0,False)        
    else:
        return (0,0,False)


def quat_dot_product(q1, q2):
    """
    takes in two quaternions and returns their dot product
    """
    return q1.x*q2.x + q1.y*q2.y + q1.z*q2.z +q1.w*q2.w


def slerp(q1, q2, t):
    """
    finds the SLERP interpolation between two quaternions
    """
    dot_product = quat_dot_product(q1,q2)
    if dot_product < 0:
        q1.w = -q1.w
        dot_product = quat_dot_product(q1, q2)
    theta = math.acos(dot_product)
    x = (math.sin((1-t)*theta)/math.sin(theta))*q1.x + (math.sin(t*theta)/math.sin(theta))*q2.x
    y = (math.sin((1-t)*theta)/math.sin(theta))*q1.y + (math.sin(t*theta)/math.sin(theta))*q2.y
    z = (math.sin((1-t)*theta)/math.sin(theta))*q1.z + (math.sin(t*theta)/math.sin(theta))*q2.z
    w = (math.sin((1-t)*theta)/math.sin(theta))*q1.w + (math.sin(t*theta)/math.sin(theta))*q2.w
    result = Quaternion()
    result.x = x
    result.y = y
    result.z = z
    result.w = w
    return result


########################################
#    IMAGE-RELATED HELPER METHODS      #
########################################

def threshold(image, hsvImg, threshImg, lowerHSV, upperHSV):
    """ 
    Thresholds an image for a certain range of hsv values 
    """ 
    cv.Smooth(image, image, cv.CV_GAUSSIAN, 3, 0)
    cv.CvtColor(image, hsvImg, cv.CV_BGR2HSV) 
    cv.InRangeS(hsvImg, lowerHSV, upperHSV, threshImg)
    cv.Erode(threshImg, threshImg, None, 2)
    cv.Dilate(threshImg, threshImg, None, 2)
    #cv.Erode(threshImg, threshImg, None, 2)    
    #cv.Dilate(threshImg, threshImg, None, 1)
    cv.Erode(threshImg, threshImg, None, 1)
    cv.Dilate(threshImg, threshImg, None, 1)
    #cv.Erode(threshImg, threshImg, None, 1)
    return threshImg

def average_vectors(v1, v2):
    """
    Finds the average of two vectors v1 and v2
    """
    result = []
    for i in range(0, len(v1)):
        result.append((v1[i]+v2[i])/2)
    return result

def find_contours(im, name):
    """ 
    Takes in a thresholded image and returns a list of the contours 
    """
    thresh = im
    im = np.asarray(im[:,:])
    contours, hierarchy = cv2.findContours(np.asarray(thresh[:,:]),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)
    return contours



##################
#   MAIN CLASS   #
##################

class ColorSegmenter():
    def __init__(self, arm, left_camera, right_camera, color1=None,color2=None, **kwargs):
        self.arm = arm
        self.tool_frame = 'tool_' + self.arm
        
        self.leftInfo = self.rightInfo = None
        self.listener = tf.TransformListener()
        self.bridge = cv_bridge.CvBridge()
        self.leftImg = self.rightImg = None

        self.locks = dict()
        self.locks['%s_leftImage' % self.arm] = Lock()
        self.locks['%s_rightImage' % self.arm] = Lock()

        rospy.Subscriber('/%s/image_rect_color'%left_camera, Image, self.leftImageCallback)
        rospy.Subscriber('/%s/image_rect_color'%right_camera, Image, self.rightImageCallback)
        rospy.Subscriber('/%s/camera_info'%left_camera, CameraInfo, self.leftInfoCallback)
        rospy.Subscriber('/%s/camera_info'%right_camera, CameraInfo, self.rightInfoCallback)

        self.quat_pub = rospy.Publisher('tape_orientation_' + self.arm, Quaternion)
        self.pose_pub = rospy.Publisher('tape_pose_' + self.arm, PoseStamped)
        self.polygon_pub = rospy.Publisher('polygon_' + self.arm, PolygonStamped)
        
        self.red_service = rospy.Service('thresh_red_' + self.arm, ThreshRed, self.threshRed)
        
        self.color1_name = color1[0]
        self.color1_hsv_lower = color1[1]
        self.color1_hsv_upper = color1[2]
        
        self.color2_name = color2[0]
        self.color2_hsv_lower = color2[1]
        self.color2_hsv_upper = color2[2]

        self.left_color1_found = False
        self.left_color2_found = False
        self.right_color1_found = False
        self.right_color2_found = False

        self.color2_left_lower_pt = None
        self.color2_left_upper_pt = None
        self.color2_right_lower_pt = None
        self.color2_right_upper_pt = None
        self.color1_left_lower_pt = None
        self.color1_left_upper_pt = None
        self.color1_right_lower_pt = None
        self.color1_right_upper_pt = None

        self.prevQuaternion = None

        
        self.right_ROI_pub = rospy.Publisher('%s_ROI_right' % self.arm, Image)
        self.right_color1_pub = rospy.Publisher('%s_%s_right' % (self.arm, self.color1_name), Image)
        self.right_color2_pub = rospy.Publisher('%s_%s_right' % (self.arm, self.color2_name), Image)
        
        self.left_ROI_pub = rospy.Publisher('%s_ROI_left' % self.arm, Image)
        self.left_color1_pub = rospy.Publisher('%s_%s_left' % (self.arm, self.color1_name), Image)
        self.left_color2_pub = rospy.Publisher('%s_%s_left' % (self.arm, self.color2_name), Image)
        
        self.show_images = kwargs.get('show_images')
        self.print_messages = kwargs.get('print_messages')
        self.show_time = kwargs.get('show_time')
    
    ################################
    #   SUBSCRIBER BOUND METHODS   #
    ################################
    def leftInfoCallback(self, info):
        """ 
        Saves the info for the left camera        
        """
        self.leftInfo = info


    def rightInfoCallback(self, info):
        """ 
        Saves the info for the right camera        
        """
        self.rightInfo = info
        

    def leftImageCallback(self, image):
        """         
        Takes in the image from the left camera and processes it 
        """
        if self.locks['%s_leftImage' % self.arm].locked_lock():
            return

        self.locks['%s_leftImage' % self.arm].acquire()

        self.t0_left = time.clock()
        left_img, left_color2, left_color1, left_color2_contour, left_color1_contour, self.left_color2_found, self.left_color1_found = self.process(image, "left")
        self.left_ROI_pub.publish(self.bridge.cv_to_imgmsg(left_img))
        self.left_color1_pub.publish(self.bridge.cv_to_imgmsg(left_color1))
        self.left_color2_pub.publish(self.bridge.cv_to_imgmsg(left_color2))
        if self.show_images:
            cv.ShowImage("%s arm left camera ROI" % self.arm, left_img)
            cv.ShowImage("%s arm left camera %s" % (self.arm, self.color2_name), left_color2)
            cv.ShowImage("%s arm left camera %s" % (self.arm, self.color1_name), left_color1)
        cv.WaitKey(3)
        self.handleBoth()
        self.left_color2_found = self.left_color1_found = False
        
        self.locks['%s_leftImage' % self.arm].release()

    def rightImageCallback(self, image):
        """ 
        Takes in the image from the right camera and processes it 
        """
        if self.locks['%s_rightImage' % self.arm].locked_lock():
            return

        self.locks['%s_rightImage' % self.arm].acquire()

        self.t0_right = time.clock()
        right_img, right_color2, right_color1, right_color2_contour, right_color1_contour, self.right_color2_found, self.right_color1_found = self.process(image, "right")
        self.right_ROI_pub.publish(self.bridge.cv_to_imgmsg(right_img))
        self.right_color1_pub.publish(self.bridge.cv_to_imgmsg(right_color1))
        self.right_color2_pub.publish(self.bridge.cv_to_imgmsg(right_color2))
        if self.show_images:
            cv.ShowImage("%s arm right camera ROI" % self.arm, right_img)
            cv.ShowImage("%s arm right camera %s" % (self.arm, self.color2_name), right_color2)
            cv.ShowImage("%s arm right camera %s" % (self.arm, self.color1_name), right_color1)
        cv.WaitKey(3)
        self.handleBoth()
        self.right_color2_found = self.right_color1_found = False

        self.locks['%s_rightImage' % self.arm].release()


    def threshRed(self, i):
        #cv.ShowImage("self.leftImg", self.leftImg)
        leftImg = cv.CloneMat(self.leftImg)
        rightImg = cv.CloneMat(self.rightImg)
        width = cv.GetSize(leftImg)[0]
        height = cv.GetSize(leftImg)[1]
        leftImg = leftImg[0:400, :]
        rightImg = rightImg[0:400, :]
        if self.show_images:
            cv.ShowImage("smaller left", leftImg)
            cv.ShowImage("smaller right", rightImg)
        leftThresh = cv.CreateImage(cv.GetSize(leftImg),8,1)
        rightThresh = cv.CreateImage(cv.GetSize(rightImg),8,1)        
        leftThresh = threshold(leftImg, leftImg, leftThresh, RED_LOWER, RED_UPPER)
        rightThresh = threshold(rightImg, rightImg, rightThresh, RED_LOWER, RED_UPPER)
        if self.show_images:
            cv.ShowImage("threshleft", leftThresh)
            cv.ShowImage("threshRight", rightThresh)
        cv.WaitKey(3)
        left_contours = find_contours(leftThresh, "left_thresh")
        right_contours = find_contours(rightThresh, "right_thresh")
        if len(left_contours) > 0 and len(right_contours)>0:
            rospy.loginfo(len(left_contours))
            rospy.loginfo(len(right_contours))
            return ThreshRedResponse(1)
        return ThreshRedResponse(0)


    def process(self, image, flag):
        """
        thresholds the image for a certain hsv range and returns the coordinates of the centroid, 
        and the coordinates of the closest point to the centroid
        """
        cv_image = self.bridge.imgmsg_to_cv(image, "bgr8")
        ROI_left, ROI_right, pixelLeft, pixelRight = self.determineROI(flag)
        if flag == "left":
            ROI = ROI_left
            pixel = pixelLeft
        elif flag == "right":
            ROI = ROI_right
            pixel = pixelRight
        heightOffset = int(pixel[1]) - HEIGHT_ROI
        widthOffset = int(pixel[0]) - WIDTH_ROI
        if heightOffset < 0:
            heightOffset = 0
        if widthOffset < 0:
            widthOffset = 0
        cv_image = cv_image[heightOffset:heightOffset+2*HEIGHT_ROI, widthOffset:widthOffset+2*WIDTH_ROI]
        if flag == "left":
            self.leftImg = cv_image
        elif flag == "right":
            self.rightImg = cv_image
        hsvImg = cv.CreateImage(cv.GetSize(cv_image),8,3)
        color1ThreshImg = cv.CreateImage(cv.GetSize(cv_image),8,1)
        color1ThreshImg = threshold(cv_image, hsvImg, color1ThreshImg, self.color1_hsv_lower, self.color1_hsv_upper)
        color2ThreshImg = cv.CreateImage(cv.GetSize(cv_image),8,1)
        color2ThreshImg = threshold(cv_image, hsvImg, color2ThreshImg, self.color2_hsv_lower, self.color2_hsv_upper)
        color2ContourImg = cv.CloneImage(color2ThreshImg)
        color1ContourImg = cv.CloneImage(color1ThreshImg)
        color2_contours = find_contours(color2ContourImg, self.color2_name) #FIXME remove later
        color1_contours = find_contours(color1ContourImg, self.color1_name) #FIXME remove later
        if flag=="left":
            self.color2_left_lower_pt, self.color2_left_upper_pt, left_color2_found = find_endpoints(color2_contours)
            self.color1_left_lower_pt, self.color1_left_upper_pt, left_color1_found = find_endpoints(color1_contours)
            self.color2_left_lower_pt = self.addOffset(self.color2_left_lower_pt, widthOffset, heightOffset)
            self.color2_left_upper_pt = self.addOffset(self.color2_left_upper_pt, widthOffset, heightOffset)
            self.color1_left_lower_pt = self.addOffset(self.color1_left_lower_pt, widthOffset, heightOffset)
            self.color1_left_upper_pt = self.addOffset(self.color1_left_upper_pt, widthOffset, heightOffset)
            color2_found = left_color2_found
            color1_found = left_color1_found
        elif flag=="right":
            self.color2_right_lower_pt, self.color2_right_upper_pt, right_color2_found = find_endpoints(color2_contours)
            self.color1_right_lower_pt, self.color1_right_upper_pt, right_color1_found = find_endpoints(color1_contours)
            self.color2_right_lower_pt = self.addOffset(self.color2_right_lower_pt, widthOffset, heightOffset)
            self.color2_right_upper_pt = self.addOffset(self.color2_right_upper_pt, widthOffset, heightOffset)
            self.color1_right_lower_pt = self.addOffset(self.color1_right_lower_pt, widthOffset, heightOffset)
            self.color1_right_upper_pt = self.addOffset(self.color1_right_upper_pt, widthOffset, heightOffset)
            color2_found = right_color2_found
            color1_found = right_color1_found
        return cv_image, color2ThreshImg, color1ThreshImg, color2ContourImg, color1ContourImg, color2_found, color1_found


    def handleBoth(self):
        """ 
        Returns the quaternion and position of the pieces of tape (which should correspond to the 
        orientation and position of the gripper 
        """
        try:
            found = self.left_color1_found and self.left_color2_found and self.right_color1_found and self.right_color2_found
            if self.print_messages:
                print "found"
                print "left_%s:\t\t%s" % (self.color1_name,self.left_color1_found)
                print "right_%s:\t\t%s" % (self.color1_name,self.right_color1_found)
                print "left_%s:\t\t%s" % (self.color2_name,self.left_color2_found)
                print "right_%s:\t\t%s" % (self.color2_name,self.right_color2_found)
            if found:
                color2_lower_pt = self.convertStereo(self.color2_left_lower_pt[0], self.color2_left_lower_pt[1], math.fabs(self.color2_left_lower_pt[0] - self.color2_right_lower_pt[0]))
                color2_upper_pt = self.convertStereo(self.color2_left_upper_pt[0], self.color2_left_upper_pt[1], math.fabs(self.color2_left_upper_pt[0] - self.color2_right_upper_pt[0]))
                color1_lower_pt = self.convertStereo(self.color1_left_lower_pt[0], self.color1_left_lower_pt[1], math.fabs(self.color1_left_lower_pt[0] - self.color1_right_lower_pt[0]))
                color1_upper_pt = self.convertStereo(self.color1_left_upper_pt[0], self.color1_left_upper_pt[1], math.fabs(self.color1_left_upper_pt[0] - self.color1_right_upper_pt[0]))
                p = Point()
                position = ((color2_lower_pt[0]+color2_upper_pt[0]+color1_lower_pt[0]+color1_upper_pt[0])/4, (color2_lower_pt[1]+color2_upper_pt[1]+color1_lower_pt[1]+color1_upper_pt[1])/4, (color2_lower_pt[2]+color2_upper_pt[2]+color1_lower_pt[2]+color1_upper_pt[2])/4)
                p.x = position[0]
                p.y = position[1]
                p.z = position[2]

                polygon_points = [color2_lower_pt, color2_upper_pt, color1_upper_pt, color1_lower_pt]
                polygon_points = [Point32(*x) for x in polygon_points]
                polygon = PolygonStamped()
                polygon.polygon.points = polygon_points
                polygon.header.frame_id = "left_BC"
                polygon.header.stamp = rospy.Time.now()
                self.polygon_pub.publish(polygon)
                color2_vector = []
                color1_vector = []
                for i in range(0, 3):
                    color2_vector.append(color2_upper_pt[i] - color2_lower_pt[i])
                    color1_vector.append(color1_upper_pt[i] - color1_lower_pt[i])
                quat = self.get_orientation_from_lines(color2_vector, color1_vector)
                tb = tfx.tb_angles(quat)
                q = Quaternion()
                q.x = quat[0]
                q.y = quat[1]
                q.z = quat[2]
                q.w = quat[3]

                if self.prevQuaternion == None:
                    self.prevQuaternion = q
                else:
                    prevQuat = tfx.tb_angles(self.prevQuaternion).msg
                    currQuat = tfx.tb_angles(q).msg
                    if SLERP:
                        try:
                            """if DYNAMIC_SLERP:
                                angle = angleBetweenQuaternions(prevQuat, currQuat)
                                print "ANGLE: "+angle
                                slerp_constant = calculateSLERPConstant(angle)
                            else:
                                slerp_constant = SLERP_CONSTANT
                            print "SLERP: "+slerp_constant"""
                            q = slerp(prevQuat, currQuat, SLERP_CONSTANT)
                        except ZeroDivisionError:
                            q = currQuat
                        self.prevQuaternion = q
                    else:
                        q = currQuat
                        self.prevQuaternion = q
                pose = PoseStamped()
                pose.pose.position = p
                pose.pose.orientation = q
                pose.header.frame_id = self.leftInfo.header.frame_id
                pose.header.stamp = rospy.Time.now()
                self.quat_pub.publish(q)
                self.pose_pub.publish(pose)
                t_left = time.clock() - self.t0_left
                t_right = time.clock() - self.t0_right
                if self.show_time:
                    print "RUNNING TIME FROM LEFT IMAGE: "+str(t_left)
                    print "RUNNING TIME FROM RIGHT IMAGE: "+str(t_right)
                if self.print_messages:                
                    print "WORKING FINE"
            else:
                #self.pose_pub.publish(self.prevQuaternion) #if the points aren't detected, continue publishing the last known location
                if self.print_messages:                
                     print "POINTS NOT DETECTED"
        except (TypeError, ValueError) as e:
            if self.print_messages:
                print "CAUGHT ERROR"    
                print e
            #self.pose_pub.publish(self.prevQuaternion) #if some kind of error comes up, continue publishing the last known location #FIXME we may want to change this behavior
            pass



    ##############################
    #       HELPER METHODS       #
    ############################## 

    ########################################
    #       RED THRESHOLD SERVER           #
    ########################################


    def determineROI(self, flag):
        """
        Determines the boundaries of a region of interest, based on 
        the pixel coordinates of the gripper as given by the inverse kinematics of the robot
        """
        pose = tfx.pose([0,0,0], [0,0,0,1], frame=self.tool_frame, stamp=rospy.Time.now())
        tf_tool_to_cam = tfx.lookupTransform('/left_BC',self.tool_frame,wait=10)        
        pose = tf_tool_to_cam * pose
        stereoModel = image_geometry.StereoCameraModel()
        stereoModel.fromCameraInfo(self.leftInfo, self.rightInfo)
        (u_l, v_l), (u_r, v_r) = stereoModel.project3dToPixel(pose.position.list)
        ROI_left = ((int(u_l-WIDTH_ROI), int(v_l-HEIGHT_ROI)), (int(u_l+WIDTH_ROI), int(v_l+HEIGHT_ROI)))
        ROI_right= ((int(u_r-WIDTH_ROI), int(v_r-HEIGHT_ROI)), (int(u_r+WIDTH_ROI), int(v_r+HEIGHT_ROI)))
        return ROI_left, ROI_right, (u_l, v_l), (u_r, v_r)
        

    def addOffset(self, pt, xOffset, yOffset):
        """
        Adds x and y offsets to a point of form (x, y)
        """
        if type(pt) == tuple:
            return (pt[0]+xOffset,pt[1]+yOffset)
        return pt


    def get_orientation_from_lines(self, v0, v1):
        """ 
        Takes in two vectors, v0 and v1, (which are KNOWN to be in the same plane) and finds 
        the normal, and creates a rotation matrix from v0, v1, and the normal; then converts this 
        rotation matrix to a quaternion 
        """
        v0, v1 = np.array(v0), np.array(v1)
        v0 = v0 / np.linalg.norm(v0) 
        v1 = v1 / np.linalg.norm(v1) 
        n = np.cross(v0, v1)
        parallel = average_vectors(v0, v1)
        parallel = parallel / np.linalg.norm(parallel)
        third = np.cross(n, parallel)
        third = third / np.linalg.norm(third)
        #n = n / np.linalg.norm(n)
        #v1 = np.cross(n, v0)
        #v1 = v1 / np.linalg.norm(v1)
        #rotMat = np.vstack((n, v1, v0)).T
        rotMat = np.vstack((parallel, third, n)).T
        matrix = rotMat
        tbRot = tfx.tb_angles(matrix).matrix        
        #tbRot = self.rotate(-90, "yaw", tbRot)    #FIXME: get correct yaw pitch roll values
        #tbRot = self.rotate(60, "pitch", tbRot)
        tbRot = self.rotate(180, "roll", tbRot)
        quat = tfx.tb_angles(tbRot).quaternion
        return list(quat)


    def rotate(self, angle, axis, matrix):
        """ 
        Takes a rotation matrix and rotates it a certain angle about a certain axis 
        """
        if axis == "yaw":
            rot = tfx.tb_angles(angle, 0, 0).matrix
        elif axis == "pitch":
            rot = tfx.tb_angles(0, angle, 0).matrix
        elif axis == "roll":
            rot = tfx.tb_angles(0, 0, angle).matrix
        return matrix*rot


    def convertStereo(self, u, v, disparity):
        """ 
        Converts two pixel coordinates u and v along with the disparity to give PointStamped 
        """
        stereoModel = image_geometry.StereoCameraModel()
        stereoModel.fromCameraInfo(self.leftInfo, self.rightInfo)
        (x,y,z) = stereoModel.projectPixelTo3d((u,v), disparity)
        return (x,y,z)


##############################
#      EXECUTION CODE        #
##############################

def main():
    rospy.init_node('color_segmenter',anonymous=True)
    rospy.sleep(5)
    
    parser = argparse.ArgumentParser()
    
    parser.add_argument('arm',nargs='?')
    parser.add_argument('--show-images','-i',action='store_true',default=False)
    parser.add_argument('--print-messages',action='store_true',default=False)
    parser.add_argument('--show-time',action='store_true',default=False)
    
    args = parser.parse_args(rospy.myargv()[1:])

    arm = args.arm or rospy.get_param('~arm','R')
    del args.arm

    if arm == 'R':
        color1 = ('orange',ORANGE_LOWER,ORANGE_UPPER)
        color2 = ('green',GREEN_LOWER,GREEN_UPPER)
    else:
        color2 = ('purple',PURPLE_LOWER,PURPLE_UPPER)
        color1 = ('blue',BLUE_LOWER,BLUE_UPPER)
                        

    
    left_camera = 'BC/left'
    right_camera = 'BC/right'

    gs = ColorSegmenter(arm, left_camera, right_camera,
                        color1=color1, color2=color2, **vars(args))

    """
    gs = ColorSegmenter('R', left_camera, right_camera,
                        color1=('orange',ORANGE_LOWER,ORANGE_UPPER),
                        color2=('green',GREEN_LOWER,GREEN_UPPER),
                        **vars(args))
    gs = ColorSegmenter('L', left_camera, right_camera,
                        color2=('purple',PURPLE_LOWER,PURPLE_UPPER),
                        color1=('blue',BLUE_LOWER,BLUE_UPPER),
                        **vars(args))
    """
    rospy.spin()


def test_cache():
    rospy.init_node('test_cache',anonymous=True)
    rospy.sleep(1)
    listener = tf.TransformListener()
    f0 = '/left_optical_frame'
    f1 = '/0_link'
    while not rospy.is_shutdown():
        try:
            common = listener.getLatestCommonTime(f0, f1)
            listener.waitForTransform(f0,f1,common,rospy.Duration(4.0))
            break
        except tf.Exception:
            rospy.loginfo('tf exception')

        rospy.sleep(.1)
        
    rospy.loginfo('found it!')

if __name__ == '__main__':
    main()
    

