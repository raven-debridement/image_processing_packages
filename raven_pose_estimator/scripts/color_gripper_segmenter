#!/usr/bin/env python

# Import required Python code.
import roslib
import argparse
roslib.load_manifest('raven_pose_estimator')
import rospy

from raven_pose_estimator.srv import *
import cv
import cv2
import numpy as np
from scipy import linalg
import math
from std_msgs.msg import String
from sensor_msgs.msg import Image, CameraInfo
import cv_bridge
from geometry_msgs.msg import Point, PointStamped, Quaternion, PoseStamped, Polygon, PolygonStamped, Point32
import tf
import image_geometry
import time
import functools

import message_filters
from threading import Lock

import tf.transformations as tft
import tfx

import IPython

from collections import namedtuple
ROI_size = namedtuple('ROI_size','width height')


# adapted and adjusted from Greg Kahn's code (ImageProcessing.py)

########################################
#             CONSTANTS                #
########################################

# right gripper
GREEN_LOWER = cv.Scalar(38, 50, 50) #THESE ARE THE GREEN PAPER VALUES
GREEN_UPPER = cv.Scalar(95, 255, 255)
ORANGE_LOWER = cv.Scalar(5, 40, 200) # THESE ARE THE ORANGE PAPER VALUES
ORANGE_UPPER = cv.Scalar(30, 255, 255)

# left gripper
PURPLE_LOWER = cv.Scalar(120, 25, 90)
PURPLE_UPPER = cv.Scalar(170, 255, 255)
BLUE_LOWER = cv.Scalar(96, 45, 120)
BLUE_UPPER = cv.Scalar(120, 255, 255)

# TEMP: since only for one gripper at a time
#GREEN_LOWER = PURPLE_LOWER
#GREEN_UPPER = PURPLE_UPPER
#ORANGE_LOWER = BLUE_LOWER
#ORANGE_UPPER = BLUE_UPPER

RED_LOWER = cv.Scalar(0, 100, 30) # VALUES FOR THE RED FOAM
RED_UPPER = cv.Scalar(3, 255, 255)

DEFAULT_ROI_SIZE = ROI_size(600,600)

SLERP = True
DYNAMIC_SLERP = False
SLERP_CONSTANT = 0.1




########################################
#     3D GEOMETRY HELPER METHODS       #
########################################


def calculateSLERPConstant(angle):
    return math.fabs(angle/360)

def angleBetweenQuaternions(quat0, quat1):
    """ 
    Returns angle between quat0 and quat1 in degrees 
    """
    q0 = np.array(quat0)
    q1 = np.array(quat1)
    theta = math.acos(2*np.dot(q0,q1)**2 - 1)
    theta = theta*(180.0/math.pi)
    return theta



def order_points(p1, p2):
    """ 
    Takes in two points of form (x,y) and orders them according to y-coordinate value 
    """
    if p1[1] > p2[1]:
        return p1,p2
    elif p1[1] < p2[1]:
        return p2,p1
    else:
        return p1,p2



def find_endpoints(contours):
    """ 
    Takes in a list of contours and returns the pixel coordinates of centroids of the top two contours 
    """
    if len(contours) < 2:
        return (0,0,False)
    contours.sort(key=len, reverse=True)
    points = []
    for c in contours:
        moments = cv2.moments(c)
        if moments['m00']!=0:
            cx = int(moments['m10']/moments['m00'])     
            cy = int(moments['m01']/moments['m00'])        
            points.append((cx, cy))
    try:
        upper_pt, lower_pt = order_points(points[0], points[1])
        return (lower_pt, upper_pt, True)
    except IndexError as e:
        return (0,0,False)        
    else:
        return (0,0,False)


def quat_dot_product(q1, q2):
    """
    takes in two quaternions and returns their dot product
    """
    return q1.x*q2.x + q1.y*q2.y + q1.z*q2.z +q1.w*q2.w


def slerp(q1, q2, t):
    """
    finds the SLERP interpolation between two quaternions
    """
    dot_product = quat_dot_product(q1,q2)
    if dot_product < 0:
        q1.w = -q1.w
        dot_product = quat_dot_product(q1, q2)
    theta = math.acos(dot_product)
    x = (math.sin((1-t)*theta)/math.sin(theta))*q1.x + (math.sin(t*theta)/math.sin(theta))*q2.x
    y = (math.sin((1-t)*theta)/math.sin(theta))*q1.y + (math.sin(t*theta)/math.sin(theta))*q2.y
    z = (math.sin((1-t)*theta)/math.sin(theta))*q1.z + (math.sin(t*theta)/math.sin(theta))*q2.z
    w = (math.sin((1-t)*theta)/math.sin(theta))*q1.w + (math.sin(t*theta)/math.sin(theta))*q2.w
    result = Quaternion()
    result.x = x
    result.y = y
    result.z = z
    result.w = w
    return result


########################################
#    IMAGE-RELATED HELPER METHODS      #
########################################

def threshold(image, hsvImg, threshImg, lowerHSV, upperHSV):
    """ 
    Thresholds an image for a certain range of hsv values 
    """ 
    cv.Smooth(image, image, cv.CV_GAUSSIAN, 3, 0)
    cv.CvtColor(image, hsvImg, cv.CV_BGR2HSV) 
    cv.InRangeS(hsvImg, lowerHSV, upperHSV, threshImg)
    cv.Erode(threshImg, threshImg, None, 2)
    cv.Dilate(threshImg, threshImg, None, 2)
    #cv.Erode(threshImg, threshImg, None, 2)    
    #cv.Dilate(threshImg, threshImg, None, 1)
    cv.Erode(threshImg, threshImg, None, 1)
    cv.Dilate(threshImg, threshImg, None, 1)
    #cv.Erode(threshImg, threshImg, None, 1)
    return threshImg

def average_vectors(v1, v2):
    """
    Finds the average of two vectors v1 and v2
    """
    result = []
    for i in range(0, len(v1)):
        result.append((v1[i]+v2[i])/2)
    return result

def find_contours(im, name):
    """ 
    Takes in a thresholded image and returns a list of the contours 
    """
    thresh = im
    im = np.asarray(im[:,:])
    contours, hierarchy = cv2.findContours(np.asarray(thresh[:,:]),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)
    return contours

class ColorSidePoints(object):
    def __init__(self):
        self.found = False
        self.upper = None
        self.lower = None

class ColorPoints(object):
    def __init__(self, name, hsv_upper, hsv_lower):
        self.name = name
        self.hsv_upper = hsv_upper
        self.hsv_lower = hsv_lower
        self.left = ColorSidePoints()
        self.right = ColorSidePoints()
    
    def __getitem__(self, name):
        return getattr(self, name)

##################
#   MAIN CLASS   #
##################

class ColorSegmenter(object):
    def __init__(self, arm, camera_name, gripper_ROI_wh, color1=None,color2=None, **kwargs):
        self.arm = arm
        self.sides = ['left','right']
        self.camera_name = camera_name
        self.camera = dict((side, '%s/%s' % (camera_name,side)) for side in self.sides)
        
        self.show_images = kwargs.get('show_images')
        self.print_messages = kwargs.get('print_messages')
        self.show_time = kwargs.get('show_time')
        
        self.tool_frame = '/tool_' + self.arm
        self.camera_frame = None
        
        self.color1 = ColorPoints(*color1)
        self.color2 = ColorPoints(*color2)
        
        
        self.locks = dict((side,Lock()) for side in self.sides)
        self.listener = tf.TransformListener()
        self.bridge = cv_bridge.CvBridge()
        
        self.info = {}
        self.img = {}
        
        self.gripper_ROI_size = ROI_size(*gripper_ROI_wh)
        self.gripper_ROI = {}
        
        self.red_ROI = {}
        
        self.t0 = {}
        
        self.prevQuaternion = None

        self.quat_pub = rospy.Publisher('tape_orientation_' + self.arm, Quaternion)
        self.pose_pub = rospy.Publisher('tape_pose_' + self.arm, PoseStamped)
        self.polygon_pub = rospy.Publisher('polygon_' + self.arm, PolygonStamped)
        
        self.gripper_ROI_pub = dict((side,rospy.Publisher('%s_ROI_%s' % (self.arm, side), Image)) for side in self.sides) 
        self.color1_pub = dict((side,rospy.Publisher('%s_%s_%s' % (self.arm, self.color1.name, side), Image)) for side in self.sides)
        self.color2_pub = dict((side,rospy.Publisher('%s_%s_%s' % (self.arm, self.color2.name, side), Image)) for side in self.sides)

        for side in self.sides:
            rospy.Subscriber('%s/camera_info' % self.camera[side], CameraInfo, functools.partial(self._infoCallback,side))
            rospy.Subscriber('%s/image_rect_color' % self.camera[side], Image, functools.partial(self._imageCallback,side))
        
        #self.red_service = rospy.Service('thresh_red_' + self.arm, ThreshRed, self.threshRed)
    
    ################################
    #   SUBSCRIBER BOUND METHODS   #
    ################################
    def _infoCallback(self, side, info):
        self.info[side] = info
        if side == 'left' and not self.camera_frame:
            self.camera_frame = info.header.frame_id
    
    def _imageCallback(self, side, image):
        """         
        Takes in the image from the camera and processes it 
        """
        if self.locks[side].locked_lock():
            return

        with self.locks[side]:

            self.t0[side] = time.clock()
            color2, color1, color2_contour, color1_contour = self.process(image, side)
            img = self.gripper_ROI[side]
            self.gripper_ROI_pub[side].publish(self.bridge.cv_to_imgmsg(img))
            self.color1_pub[side].publish(self.bridge.cv_to_imgmsg(color1))
            self.color2_pub[side].publish(self.bridge.cv_to_imgmsg(color2))
            if self.show_images:
                cv.ShowImage("%s arm %s camera ROI" % (self.arm, side), img)
                cv.ShowImage("%s arm %s camera %s" % (self.arm, side, self.color2.name), color2)
                cv.ShowImage("%s arm %s camera %s" % (self.arm, side, self.color1.name), color1)
            cv.WaitKey(3)
            self.handleBoth()
            self.color2[side].found = self.color1[side].found = False


    def threshRed(self, i):
        #cv.ShowImage("self.leftImg", self.leftImg)
        leftImg = cv.CloneMat(self.leftImg)
        rightImg = cv.CloneMat(self.rightImg)
        width = cv.GetSize(leftImg)[0]
        height = cv.GetSize(leftImg)[1]
        leftImg = leftImg[0:400, :]
        rightImg = rightImg[0:400, :]
        if self.show_images:
            cv.ShowImage("smaller left", leftImg)
            cv.ShowImage("smaller right", rightImg)
        leftThresh = cv.CreateImage(cv.GetSize(leftImg),8,1)
        rightThresh = cv.CreateImage(cv.GetSize(rightImg),8,1)        
        leftThresh = threshold(leftImg, leftImg, leftThresh, RED_LOWER, RED_UPPER)
        rightThresh = threshold(rightImg, rightImg, rightThresh, RED_LOWER, RED_UPPER)
        if self.show_images:
            cv.ShowImage("threshleft", leftThresh)
            cv.ShowImage("threshRight", rightThresh)
        cv.WaitKey(3)
        left_contours = find_contours(leftThresh, "left_thresh")
        right_contours = find_contours(rightThresh, "right_thresh")
        if len(left_contours) > 0 and len(right_contours)>0:
            rospy.loginfo(len(left_contours))
            rospy.loginfo(len(right_contours))
            return ThreshRedResponse(1)
        return ThreshRedResponse(0)


    def process(self, image, side):
        """
        thresholds the image for a certain hsv range and returns the coordinates of the centroid, 
        and the coordinates of the closest point to the centroid
        """
        cv_image = self.bridge.imgmsg_to_cv(image, "bgr8")
        self.img[side] = cv_image
        
        ROI, pixel = self.determineROI(side)
        
        ROI_height = self.gripper_ROI_size.height
        ROI_width = self.gripper_ROI_size.width
        
        heightOffset = int(pixel[1]) - ROI_height
        widthOffset = int(pixel[0]) - ROI_width
        if heightOffset < 0:
            heightOffset = 0
        if widthOffset < 0:
            widthOffset = 0
        cv_image = cv_image[heightOffset:heightOffset+2*ROI_height, widthOffset:widthOffset+2*ROI_width]
        
        self.gripper_ROI[side] = cv_image
        
        hsvImg = cv.CreateImage(cv.GetSize(cv_image),8,3)
        color1ThreshImg = cv.CreateImage(cv.GetSize(cv_image),8,1)
        color1ThreshImg = threshold(cv_image, hsvImg, color1ThreshImg, self.color1.hsv_lower, self.color1.hsv_upper)
        color2ThreshImg = cv.CreateImage(cv.GetSize(cv_image),8,1)
        color2ThreshImg = threshold(cv_image, hsvImg, color2ThreshImg, self.color2.hsv_lower, self.color2.hsv_upper)
        color2ContourImg = cv.CloneImage(color2ThreshImg)
        color1ContourImg = cv.CloneImage(color1ThreshImg)
        color2_contours = find_contours(color2ContourImg, self.color2.name) #FIXME remove later
        color1_contours = find_contours(color1ContourImg, self.color1.name) #FIXME remove later
        self.color2[side].lower, self.color2[side].upper, self.color2[side].found = find_endpoints(color2_contours)
        self.color1[side].lower, self.color1[side].upper, self.color1[side].found = find_endpoints(color1_contours)
        self.color2[side].lower = self.addOffset(self.color2[side].lower, widthOffset, heightOffset)
        self.color2[side].upper = self.addOffset(self.color2[side].upper, widthOffset, heightOffset)
        self.color1[side].lower = self.addOffset(self.color1[side].lower, widthOffset, heightOffset)
        self.color1[side].upper = self.addOffset(self.color1[side].upper, widthOffset, heightOffset)
        return color2ThreshImg, color1ThreshImg, color2ContourImg, color1ContourImg


    def handleBoth(self):
        """ 
        Returns the quaternion and position of the pieces of tape (which should correspond to the 
        orientation and position of the gripper 
        """
        try:
            found = self.color1.left.found and self.color2.left.found and self.color1.right.found and self.color2.right.found
            if self.print_messages:
                print "found"
                print "left_%s:\t\t%s" % (self.color1.name,self.color1.left.found)
                print "right_%s:\t\t%s" % (self.color1.name,self.color1.right.found)
                print "left_%s:\t\t%s" % (self.color2.name,self.color2.left.found)
                print "right_%s:\t\t%s" % (self.color2.name,self.color2.right.found)
            if found:
                color2_lower_pt = self.convertStereo(self.color2.left.lower[0], self.color2.left.lower[1], math.fabs(self.color2.left.lower[0] - self.color2.right.lower[0]))
                color2_upper_pt = self.convertStereo(self.color2.left.upper[0], self.color2.left.upper[1], math.fabs(self.color2.left.upper[0] - self.color2.right.upper[0]))
                color1_lower_pt = self.convertStereo(self.color1.left.lower[0], self.color1.left.lower[1], math.fabs(self.color1.left.lower[0] - self.color1.right.lower[0]))
                color1_upper_pt = self.convertStereo(self.color1.left.upper[0], self.color1.left.upper[1], math.fabs(self.color1.left.upper[0] - self.color1.right.upper[0]))
                p = Point()
                position = ((color2_lower_pt[0]+color2_upper_pt[0]+color1_lower_pt[0]+color1_upper_pt[0])/4, (color2_lower_pt[1]+color2_upper_pt[1]+color1_lower_pt[1]+color1_upper_pt[1])/4, (color2_lower_pt[2]+color2_upper_pt[2]+color1_lower_pt[2]+color1_upper_pt[2])/4)
                p.x = position[0]
                p.y = position[1]
                p.z = position[2]

                polygon_points = [color2_lower_pt, color2_upper_pt, color1_upper_pt, color1_lower_pt]
                polygon_points = [Point32(*x) for x in polygon_points]
                polygon = PolygonStamped()
                polygon.polygon.points = polygon_points
                polygon.header.frame_id = "left_BC"
                polygon.header.stamp = rospy.Time.now()
                self.polygon_pub.publish(polygon)
                color2_vector = []
                color1_vector = []
                for i in range(0, 3):
                    color2_vector.append(color2_upper_pt[i] - color2_lower_pt[i])
                    color1_vector.append(color1_upper_pt[i] - color1_lower_pt[i])
                quat = self.get_orientation_from_lines(color2_vector, color1_vector)
                tb = tfx.tb_angles(quat)
                q = Quaternion()
                q.x = quat[0]
                q.y = quat[1]
                q.z = quat[2]
                q.w = quat[3]

                if self.prevQuaternion == None:
                    self.prevQuaternion = q
                else:
                    prevQuat = tfx.tb_angles(self.prevQuaternion).msg
                    currQuat = tfx.tb_angles(q).msg
                    if SLERP:
                        try:
                            """if DYNAMIC_SLERP:
                                angle = angleBetweenQuaternions(prevQuat, currQuat)
                                print "ANGLE: "+angle
                                slerp_constant = calculateSLERPConstant(angle)
                            else:
                                slerp_constant = SLERP_CONSTANT
                            print "SLERP: "+slerp_constant"""
                            q = slerp(prevQuat, currQuat, SLERP_CONSTANT)
                        except ZeroDivisionError:
                            q = currQuat
                        self.prevQuaternion = q
                    else:
                        q = currQuat
                        self.prevQuaternion = q
                pose = PoseStamped()
                pose.pose.position = p
                pose.pose.orientation = q
                pose.header.frame_id = self.camera_frame
                pose.header.stamp = rospy.Time.now()
                self.quat_pub.publish(q)
                self.pose_pub.publish(pose)
                t_left = time.clock() - self.t0['left']
                t_right = time.clock() - self.t0['right']
                if self.show_time:
                    print "RUNNING TIME FROM LEFT IMAGE: "+str(t_left)
                    print "RUNNING TIME FROM RIGHT IMAGE: "+str(t_right)
                if self.print_messages:                
                    print "WORKING FINE"
            else:
                #self.pose_pub.publish(self.prevQuaternion) #if the points aren't detected, continue publishing the last known location
                if self.print_messages:                
                     print "POINTS NOT DETECTED"
        except (TypeError, ValueError) as e:
            if self.print_messages:
                print "CAUGHT ERROR"    
                print e
            #self.pose_pub.publish(self.prevQuaternion) #if some kind of error comes up, continue publishing the last known location #FIXME we may want to change this behavior
            pass



    ##############################
    #       HELPER METHODS       #
    ############################## 

    ########################################
    #       RED THRESHOLD SERVER           #
    ########################################


    def determineROI(self, side=None):
        """
        Determines the boundaries of a region of interest, based on 
        the pixel coordinates of the gripper as given by the inverse kinematics of the robot
        """
        ROI_width = self.gripper_ROI_size.width
        ROI_height = self.gripper_ROI_size.height
        
        pose = tfx.pose([0,0,0], [0,0,0,1], frame=self.tool_frame, stamp=rospy.Time.now())
        tf_tool_to_cam = tfx.lookupTransform(self.camera_frame,self.tool_frame,wait=10)
        pose = tf_tool_to_cam * pose
        stereoModel = image_geometry.StereoCameraModel()
        stereoModel.fromCameraInfo(self.info['left'], self.info['right'])
        (u_l, v_l), (u_r, v_r) = stereoModel.project3dToPixel(pose.position.list)
        ROI_left = ((int(u_l-ROI_width), int(v_l-ROI_height)), (int(u_l+ROI_width), int(v_l+ROI_height)))
        ROI_right= ((int(u_r-ROI_width), int(v_r-ROI_height)), (int(u_r+ROI_width), int(v_r+ROI_height)))
        ROI = {'left': ROI_left, 'right': ROI_right}
        uv = {'left': (u_l, v_l), 'right': (u_r, v_r)}
        if side is None:
            return ROI, uv
        else:
            return ROI[side], uv[side]
        

    def addOffset(self, pt, xOffset, yOffset):
        """
        Adds x and y offsets to a point of form (x, y)
        """
        if type(pt) == tuple:
            return (pt[0]+xOffset,pt[1]+yOffset)
        return pt


    def get_orientation_from_lines(self, v0, v1):
        """ 
        Takes in two vectors, v0 and v1, (which are KNOWN to be in the same plane) and finds 
        the normal, and creates a rotation matrix from v0, v1, and the normal; then converts this 
        rotation matrix to a quaternion 
        """
        v0, v1 = np.array(v0), np.array(v1)
        v0 = v0 / np.linalg.norm(v0) 
        v1 = v1 / np.linalg.norm(v1) 
        n = np.cross(v0, v1)
        parallel = average_vectors(v0, v1)
        parallel = parallel / np.linalg.norm(parallel)
        third = np.cross(n, parallel)
        third = third / np.linalg.norm(third)
        #n = n / np.linalg.norm(n)
        #v1 = np.cross(n, v0)
        #v1 = v1 / np.linalg.norm(v1)
        #rotMat = np.vstack((n, v1, v0)).T
        rotMat = np.vstack((parallel, third, n)).T
        matrix = rotMat
        tbRot = tfx.tb_angles(matrix).matrix        
        #tbRot = self.rotate(-90, "yaw", tbRot)    #FIXME: get correct yaw pitch roll values
        #tbRot = self.rotate(60, "pitch", tbRot)
        tbRot = self.rotate(180, "roll", tbRot)
        quat = tfx.tb_angles(tbRot).quaternion
        return list(quat)


    def rotate(self, angle, axis, matrix):
        """ 
        Takes a rotation matrix and rotates it a certain angle about a certain axis 
        """
        if axis == "yaw":
            rot = tfx.tb_angles(angle, 0, 0).matrix
        elif axis == "pitch":
            rot = tfx.tb_angles(0, angle, 0).matrix
        elif axis == "roll":
            rot = tfx.tb_angles(0, 0, angle).matrix
        return matrix*rot


    def convertStereo(self, u, v, disparity):
        """ 
        Converts two pixel coordinates u and v along with the disparity to give PointStamped 
        """
        stereoModel = image_geometry.StereoCameraModel()
        stereoModel.fromCameraInfo(self.info['left'], self.info['right'])
        (x,y,z) = stereoModel.projectPixelTo3d((u,v), disparity)
        return (x,y,z)


##############################
#      EXECUTION CODE        #
##############################

def main():
    rospy.init_node('color_segmenter',anonymous=True)
    rospy.sleep(5)
    
    parser = argparse.ArgumentParser()
    
    parser.add_argument('arm',nargs='?')
    parser.add_argument('--show-images','-i',action='store_true',default=False)
    parser.add_argument('--print-messages',action='store_true',default=False)
    parser.add_argument('--show-time',action='store_true',default=False)
    
    args = parser.parse_args(rospy.myargv()[1:])

    arm = args.arm or rospy.get_param('~arm','R')
    del args.arm

    if arm == 'R':
        color1 = ('orange',ORANGE_LOWER,ORANGE_UPPER)
        color2 = ('green',GREEN_LOWER,GREEN_UPPER)
    else:
        color2 = ('purple',PURPLE_LOWER,PURPLE_UPPER)
        color1 = ('blue',BLUE_LOWER,BLUE_UPPER)
                        

    
    camera_name = 'BC'

    gs = ColorSegmenter(arm, camera_name, DEFAULT_ROI_SIZE,
                        color1=color1, color2=color2, **vars(args))

    """
    gs = ColorSegmenter('R', left_camera, right_camera,
                        color1=('orange',ORANGE_LOWER,ORANGE_UPPER),
                        color2=('green',GREEN_LOWER,GREEN_UPPER),
                        **vars(args))
    gs = ColorSegmenter('L', left_camera, right_camera,
                        color2=('purple',PURPLE_LOWER,PURPLE_UPPER),
                        color1=('blue',BLUE_LOWER,BLUE_UPPER),
                        **vars(args))
    """
    rospy.spin()


def test_cache():
    rospy.init_node('test_cache',anonymous=True)
    rospy.sleep(1)
    listener = tf.TransformListener()
    f0 = '/left_optical_frame'
    f1 = '/0_link'
    while not rospy.is_shutdown():
        try:
            common = listener.getLatestCommonTime(f0, f1)
            listener.waitForTransform(f0,f1,common,rospy.Duration(4.0))
            break
        except tf.Exception:
            rospy.loginfo('tf exception')

        rospy.sleep(.1)
        
    rospy.loginfo('found it!')

if __name__ == '__main__':
    main()
    

