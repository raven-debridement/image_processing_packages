#!/usr/bin/env python

# Import required Python code.
import roslib
roslib.load_manifest('raven_pose_estimator')
import rospy

import cv
import cv2
import numpy as np
from scipy import linalg
import math
from std_msgs.msg import String
from sensor_msgs.msg import Image, CameraInfo
import cv_bridge
from geometry_msgs.msg import Point, PointStamped
import tf
import image_geometry
import time

import message_filters
from threading import Lock

import tf.transformations as tft
import tfx

import code

# adapted and adjusted from Greg Kahn's code (ImageProcessing.py)

########################################
#             CONSTANTS                #
########################################

#TRANSLATION_R2L = (-0.05137, 0, 0.00136) #FIXME stick in translation and rotation matrices
#ROTATION_R2L = (0, -0.108380311, 0)
TRANSLATION_R2L = (-0.129296, 0, 0.00136124)
ROTATION_R2L = (0,0.104719755,0)
ORANGE_LOWER = cv.Scalar( 6, 100, 100)
ORANGE_UPPER = cv.Scalar(13, 255, 255)
BLUE_LOWER = cv.Scalar(108,100, 180)
BLUE_UPPER = cv.Scalar(115,255, 255)


########################################
#    IMAGE-RELATED HELPER METHODS      #
########################################

""" thresholds an image for a certain range of hsv values """ #FIXME: does eroding and dilating cause a big performance hit?
def threshold(image, hsvImg, threshImg, lowerHSV, upperHSV):
    cv.Smooth(image, image, cv.CV_GAUSSIAN, 3, 0)
    cv.CvtColor(image, hsvImg, cv.CV_BGR2HSV) 
    cv.InRangeS(hsvImg, lowerHSV, upperHSV, threshImg)
    cv.Erode(threshImg, threshImg, None, 1)    
    cv.Dilate(threshImg, threshImg, None, 1)

    #cv.ShowImage("thresh", threshImg)
    #cv.WaitKey(3)
    return threshImg

########################################
#     3D GEOMETRY HELPER METHODS       #
########################################

def flip_origin(point, height):
    x = point[0]
    y = point[1]
    result_x = x
    result_y = height-y
    return (result_x, result_y)

def flip_line(line, height):
    (x1, y1) = flip_origin((line[0], line[1]), 1280)
    (x2, y2) = flip_origin((line[2], line[3]), 1280)
    return (x1, y1, x2, y2)

def angleBetweenQuaternions(quat0, quat1):
    """
    Returns angle between quat0 and quat1 in degrees
    """
    q0 = np.array(quat0)
    q1 = np.array(quat1)
    theta = math.acos(2*np.dot(q0,q1)**2 - 1)
    theta = theta*(180.0/math.pi)
    return theta

def invert_vector(v):
    result = [-t for t in v]
    return result

""" finds lines in a binary image using hough line transform, after running canny edge detection """	
def find_line(image, flag):
    #---- FIT LINE METHOD -----#    
    contours, hier = cv2.findContours(np.asarray(image[:,:]), cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)
    cnt = contours[0]
    [vx, vy, x, y] = cv.FitLine(cv.fromarray(cnt), cv.CV_DIST_FAIR,0,0.01,0.01)
    #print flag
    #print "X, Y, VX, VY"
    #print x
    #print y
    #print vx
    #print vy
    endpoint_separation = 100
    lefty = int((vy/vx)*(-int(endpoint_separation/2))+y)
    righty = int((vy/vx)*(int(endpoint_separation/2))+y)
    line = (x-int(endpoint_separation/2), lefty, x+int(endpoint_separation/2), righty)
    show = np.asarray(image[:,:])
    #cv2.line(show, (int(line[0]), int(line[1])), (int(line[2]), int(line[3])), 255, 2)
    cv2.line(show, (int(x), int(y)), (int(x+15), int(y+(vy/vx)*15)), 255, 2)
    return ((flip_line(line,1280),), cv.fromarray(show))
    #return ((line,), cv.fromarray(show))
    #---- HOUGH LINES METHOD ----#
    #edges = cv2.Canny(np.asarray(image[:,:]), 80, 120)
    #lines = cv2.HoughLinesP(edges, 1, math.pi/180, 1, None, 20, 1)
    #flipped_lines = []
    #if lines != None:
	#for line in lines[0]:
	 #   flipped_lines.append(flip_line(line, 1280))
    #return (lines, cv.fromarray(edges))

""" finds the distance between two points """
def distance(x1, y1, x2, y2):
    return ((x2-x1)**2+(y2-y1)**2)**0.5

""" given a list of lines in (x1, y1, x2, y2) form, finds the longest line """
def get_max_line(lines): 
    lengths = []
    for line in lines:
	lengths.append(distance(line[0], line[1], line[2], line[3]))
    max_length = max(lengths)
    i = lengths.index(max_length)
    return lines[i]

""" takes in translation and rotation vectors and a plane, and transforms the plane accordingly """
def transform_plane(translation, rotation, plane):
    result_plane = (rotate_vector(rotation, plane[0]), (plane[1][0]+translation[0], plane[1][1]+translation[1], plane[1][2]+translation[2])) #FIXME get the translation and rotation working properly
    #print "TRANSFORMED"
    #print result_plane[0]
    return result_plane

""" where a plane is the tuple (normal, point); returns unit vector corresponding to the normal of the intersection of two planes """
def intersect_planes(plane1, plane2):    
    cross_product = np.cross(plane1[0], plane2[0])
    #cross_product = np.cross(plane2[0], plane1[0])
    return cross_product
	
""" helper function to rotate a vector given yaw-pitch-roll values """ #FIXME looks like a place where an error might be
def rotate_vector(yaw_pitch_roll, vector):
    a = yaw_pitch_roll[0]
    b = yaw_pitch_roll[1]
    c = yaw_pitch_roll[2]
    rot_matrix = np.array([[math.cos(a)*math.cos(b), math.cos(a)*math.sin(b)*math.sin(c)-math.sin(a)*math.cos(c), math.cos(a)*math.sin(b)*math.cos(c)+math.sin(a)*math.sin(c)], [math.sin(a)*math.cos(b), math.sin(a)*math.sin(b)*math.sin(c)+math.cos(a)*math.cos(c), math.sin(a)*math.sin(b)*math.cos(c)-math.cos(a)*math.sin(c)], [-math.sin(b), math.cos(b)*math.sin(c), math.cos(b)*math.cos(c)]])
    rot_matrix.reshape((3,3))
    #print "ROTATION MATRIX"
    #print rot_matrix
    result = rot_matrix*vector
    return result

##################
#   MAIN CLASS   #
##################

class ColorSegmenter():
    def __init__(self, left_camera, right_camera):
        
        self.leftInfo = self.rightInfo = None

        self.foundColorLeft = False
        self.foundColorRight = False
	
        self.listener = tf.TransformListener()
	self.bridge = cv_bridge.CvBridge()

        rospy.Subscriber('/stereo/%s/image_rect_color'%left_camera, Image, self.leftImageCallback)
        rospy.Subscriber('/stereo/%s/image_rect_color'%right_camera, Image, self.rightImageCallback)
        rospy.Subscriber('/stereo/%s/camera_info'%left_camera, CameraInfo, self.leftInfoCallback)
        rospy.Subscriber('/stereo/%s/camera_info'%right_camera, CameraInfo, self.rightInfoCallback)
	self.blue_right_lines = []
	self.orange_right_lines = []
	self.blue_left_lines = []
	self.orange_left_lines = []
	self.left_orange_found = False
	self.left_blue_found = False
	self.right_orange_found = False
	self.right_blue_found = False
	self.prev_quat = None
    
    ################################
    #   SUBSCRIBER BOUND METHODS   #
    ################################
    def leftInfoCallback(self, info):
	""" saves the info for the left camera	"""
        self.leftInfo = info

    def rightInfoCallback(self, info):
	""" saves the info for the right camera	"""
        self.rightInfo = info

    def leftImageCallback(self, image):
	""" """
	#left_edges, self.foundColorLeft, self.left_lines = self.process(image, "left")
	self.blue_left_lines, self.blue_left_edges, self.left_blue_found,self.orange_left_lines, self.orange_left_edges,self.left_orange_found, blue_left_thresh, orange_left_thresh = self.process(image, "left")
	self.handleBoth()
        #cv.ShowImage('Left Orange Thresholded', orange_left_thresh)
	#cv.ShowImage('Left Blue Thresholded', blue_left_thresh)
	#cv.ShowImage('Left Orange Edges', self.orange_left_edges)
	#cv.ShowImage('Left Blue Edges', self.blue_left_edges)
	#cv.ShowImage('lines', image)
        cv.WaitKey(3)

    def rightImageCallback(self, image):
	""" """
	self.blue_right_lines, self.blue_right_edges,self.right_blue_found, self.orange_right_lines, self.orange_right_edges ,self.right_orange_found, blue_right_thresh, orange_right_thresh = self.process(image, "right")
	self.handleBoth()
        #cv.ShowImage('Right Viewer', right_thresh)
	#cv.ShowImage('Right Edges', right_edges)
        #cv.WaitKey(3)

    def handleBoth(self):
	""" returns the unit vector corresponding to the orientation of the colored tape """
	if self.left_orange_found and self.left_blue_found and self.right_orange_found and self.right_blue_found:
	    #blue_vector = self.find_unit_vector(self.blue_left_lines[0], self.blue_right_lines[0], "blue")
	    #orange_vector = self.find_unit_vector(self.orange_left_lines[0], self.orange_right_lines[0], "orange")
	    blue_vector = self.find_unit_vector(self.blue_left_lines, self.blue_right_lines, "blue")
	    orange_vector = self.find_unit_vector(self.orange_left_lines, self.orange_right_lines, "orange")
	    #blue_vector = invert_vector(blue_vector)
	    #orange_vector = invert_vector(orange_vector)
	    quat = self.get_orientation_from_lines(blue_vector, orange_vector)
	    print "POSE"
	    print "------------------------------"
	    #print "vectors"
	    #print blue_vector
	    #print orange_vector
	    print "quaternion"
	    print quat
	    print "yaw pitch roll"
	    print tfx.tb_angles(quat)
	    print tfx.tb_angles(quat).matrix
	    if self.prev_quat != None:
		angle = angleBetweenQuaternions(self.prev_quat, quat) #FIXME uncomment this
		print "angle"
		print angle
	    print "\n"
	    self.prev_quat = quat

    ##############################
    #       HELPER METHODS       #
    ##############################
    def find_unit_vector(self, left_lines, right_lines, color):
        longest_left = get_max_line(left_lines)
        longest_right = get_max_line(right_lines)
        left_plane = self.transform_to_world(longest_left, "left") 
        right_plane = self.transform_to_world(longest_right, "right")
	#print color
	#print "PLANE"
	#print left_plane
	#print right_plane
        transformed_plane = transform_plane(TRANSLATION_R2L, ROTATION_R2L, right_plane) 
	unit_vector = self.average_vectors(left_plane[0], right_plane[0])
        #unit_vector = intersect_planes(transformed_plane, left_plane)
	print "UNIT_VECTOR"
	print color
	unit_vector = self.normalize(unit_vector)
	print unit_vector
        return np.asarray(unit_vector)     
	 
    def average_vectors(self, v1, v2):
	result = []
	for i in range(0, len(v1)):
	    result.append((v1[i]+v2[i])/2)
	return result
   
    def process(self, image, flag):
	"""
	thresholds the image for a certain hsv range and returns the coordinates of the centroid, 
	and the coordinates of the closest point to the centroid
	"""
	cv_image = self.bridge.imgmsg_to_cv(image, "bgr8")
	orangeThreshImg = cv.CreateImage((1280,960),8,1)
	hsvImg = cv.CreateImage((1280,960),8,3)
	orangeThreshImg = threshold(cv_image, hsvImg, orangeThreshImg, ORANGE_LOWER, ORANGE_UPPER)
	#cv.ShowImage("orange", orangeThreshImg)
	#cv.WaitKey(3)
        f = "orange_" + flag
	(orange_line, orange_edges) = find_line(orangeThreshImg, f)
	#cv.ShowImage("orange", orangeThreshImg)
	#cv.WaitKey(3)
	blueThreshImg = cv.CreateImage((1280,960),8,1)
	blueThreshImg = threshold(cv_image, hsvImg, blueThreshImg, BLUE_LOWER, BLUE_UPPER)
	#cv.ShowImage("blue", blueThreshImg)
	#cv.WaitKey(3)
        g = "blue_" + flag
	(blue_line, blue_edges) = find_line(blueThreshImg, g)
	blue_found = (blue_line!=None)
	orange_found = (orange_line!=None)
	return (blue_line, blue_edges, blue_found, orange_line, orange_edges, orange_found, blueThreshImg, orangeThreshImg)

    def transform_to_world(self, line, flag):
	""" takes in a pixel line as defined by two endpoints and transforms it to real-world coordinates based on camera info"""
	if flag == "right":
	    info = self.rightInfo
	elif flag == "left":
	    info = self.leftInfo
	x1 = line[0]
	y1 = line[1]
	x2 = line[2]
	y2 = line[3]
	#print "points"
	#print x1, y1
	#print x2, y2
	pinhole_model = image_geometry.PinholeCameraModel()
	pinhole_model.fromCameraInfo(info)	
	ray1 = pinhole_model.projectPixelTo3dRay((x1, y1))
	ray2 = pinhole_model.projectPixelTo3dRay((x2, y2))
	#print flag
	#print "rays"
	#print ray1
	#print ray2
	#plane_normal = np.cross(ray1, ray2)	
 	plane_normal = self.cross_product(ray1, ray2)
	norm = ((plane_normal[0])**2+(plane_normal[1])**2+(plane_normal[2])**2)**0.5
 	normalized = []
	for i in range(0, len(plane_normal)):
	    normalized.append(plane_normal[i]/norm)
	#print "PLANE NORMAL"
	#print normalized
	return (normalized, (0,0,0))
    
    def normalize(self, vector):
	norm = ((vector[0])**2+(vector[1])**2+(vector[2])**2)**0.5
 	normalized = []
	for i in range(0, len(vector)):
	    normalized.append(vector[i]/norm)
	return normalized
  
    def cross_product(self, v1, v2):
        x = v1[1]*v2[2]-v1[2]*v2[1]
	y = -(v1[0]*v2[2]-v2[0]*v1[2])
        z = v1[0]*v2[1]-v2[0]*v1[1]
	return (x,y,z)

    def get_orientation_from_lines(self, v0, v1):
        """
        v0 and v1 are vectors representing two lines
        that are KNOWN to be in the same plane
        """
        # get into an np array
	#v1 = invert_vector(v1)
	#v0 = invert_vector(v0)
	print "vectors"
        v0, v1 = np.array(v0), np.array(v1)
	#print "DOT PRODUCT"
	print v0
	print v1
	#print np.dot(v0,v1)
        # normalize
        v0 = v0 / np.linalg.norm(v0) 
        v1 = v1 / np.linalg.norm(v1) 
	print v0
	print v1
        # find normal
        n = np.cross(v0, v1)
	#print "NORMAL"
	#print n
	#n = np.cross(v1, v0)
        # stack into a matrix
        #rotMat = np.vstack((n, v0, v1)).T
	rotMat = np.vstack((v0, v1, n)).T
	#print "ROTMAT"
	#print rotMat
	matrix = rotMat
	matrix = linalg.orth(rotMat) #FIXME uncomment
	#print "matrices"
	#print rotMat
	#print orthogonalized
        # find the quaternion xyzw
        tbRot = tfx.tb_angles(matrix)
        quat = tbRot.quaternion
        #code.interact(local=locals())
        return list(quat)

##############################
#      EXECUTION CODE        #
##############################

def main():
    rospy.init_node('color_segmenter')
    left_camera = 'left'
    right_camera = 'right'
    gs = ColorSegmenter(left_camera, right_camera)
    rospy.spin()


if __name__ == '__main__':
    #test_everything()
    main()
    #test_orientation()
